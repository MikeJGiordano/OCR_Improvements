{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cb1de22",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbac058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from google.cloud import vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c588b594",
   "metadata": {},
   "source": [
    "Authenticate Google Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3188f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'client_file_vision_ai_demo.json'\n",
    "client = vision.ImageAnnotatorClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d11055a",
   "metadata": {},
   "source": [
    "Define the image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1424b038",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/Users/michaelgiordano/Documents/Research/Leander_Heldring/OCR_Improvements/google_vision_ai_demo/images/1888_Page_161.png'\n",
    "cvimage = cv2.imread(image_path)\n",
    "_, encoded_image = cv2.imencode('.png', cvimage)\n",
    "api_image = vision.Image(content=encoded_image.tobytes())\n",
    "response = client.text_detection(image = api_image)\n",
    "texts = response.text_annotations\n",
    "\n",
    "for text in texts:\n",
    "    # print (text.description)\n",
    "    vertices = np.array(\n",
    "        [(vertex.x, vertex.y) \n",
    "             for vertex in text.bounding_poly.vertices\n",
    "        ])\n",
    "    # We are using cv2 rectnagle method to draw bounding boxes\n",
    "    # that requires 2 points on the image to draw the box\n",
    "    # The top,left co-ordinates and bottom,right co-ordindates of the box\n",
    "    # We can get those using the code below. \n",
    "    xmin, xmax = min(vertices[:, 0]), max(vertices[:, 0])\n",
    "    ymin, ymax = min(vertices[:, 1]), max(vertices[:, 1])\n",
    "    \n",
    "    cv2.rectangle(cvimage, (xmin, ymin), (xmax, ymax), (0, 255, 0), 1)\n",
    "\n",
    "if response.error.message:\n",
    "    print(response.error.message)\n",
    "\n",
    "plt.figure(figsize=(20, 40))\n",
    "plt.imshow(cvimage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cafc8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.open(image_path, 'rb') as image_file:\n",
    "    content = image_file.read()\n",
    "image = vision.Image(content=content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1527a9",
   "metadata": {},
   "source": [
    "Get the response back from Cloud Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aefb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.text_detection(image=image)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cf13c5",
   "metadata": {},
   "source": [
    "This is my attempt at trying to extract specific information from Cloud Vision's response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0214c449",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in response.text_annotations:\n",
    "    print(text.bounding_poly)\n",
    "    print(text.score)\n",
    "    print(text.description)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "google_vision_ai_demo",
   "language": "python",
   "name": "google_vision_ai_demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
